好的！我将以最基础的视角，从零开始，**不跳过任何步骤**，用**具体例子**和**详细计算过程**带你一步步理解 Krylov 子空间方法（尤其是 GMRES 和 CG 方法）。我们从线性代数基础开始，逐步过渡到算法实现。

---

## **第一步：线性代数基础复习**
### **1.1 向量与矩阵**
- **向量**：一组数的排列，如 $\mathbf{v} = [1, 2, 3]^T$。
- **矩阵**：数的二维排列，如 $A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix}$。
- **矩阵-向量乘法**：$A\mathbf{x}$ 表示对向量 $\mathbf{x}$ 的线性变换。

#### **例子：矩阵-向量乘法**
设 $A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix}$，$\mathbf{x} = [5, 6]^T$，则：
$$
A\mathbf{x} = \begin{bmatrix} 1 \cdot 5 + 2 \cdot 6 \\ 3 \cdot 5 + 4 \cdot 6 \end{bmatrix} = \begin{bmatrix} 17 \\ 39 \end{bmatrix}
$$

---

### **1.2 向量内积与正交性**
- **内积**：$\mathbf{u}^T \mathbf{v} = u_1v_1 + u_2v_2 + \dots + u_nv_n$。
- **正交**：若 $\mathbf{u}^T \mathbf{v} = 0$，则 $\mathbf{u}$ 和 $\mathbf{v}$ 正交。

#### **例子：正交向量**
$\mathbf{u} = [1, 0]^T$，$\mathbf{v} = [0, 1]^T$，则：
$$
\mathbf{u}^T \mathbf{v} = 1 \cdot 0 + 0 \cdot 1 = 0 \quad \text{（正交）}
$$

---

### **1.3 线性方程组**
目标：解 $A\mathbf{x} = \mathbf{b}$，即找到 $\mathbf{x}$ 使得矩阵 $A$ 与 $\mathbf{x}$ 的乘积等于 $\mathbf{b}$。

#### **例子：简单方程组**
设 $A = \begin{bmatrix} 1 & 1 \\ 0 & 1 \end{bmatrix}$，$\mathbf{b} = [3, 2]^T$，则解为：
$$
\mathbf{x} = \begin{bmatrix} 1 \\ 2 \end{bmatrix} \quad \text{（因为 } A\mathbf{x} = [1+2, 0+2]^T = [3, 2]^T \text{）}
$$

---

## **第二步：Krylov 子空间方法的核心思想**
### **2.1 投影方法（Projection Methods）**
- **目标**：将大规模问题 $A\mathbf{x} = \mathbf{b}$ 转化为低维子空间中的近似问题。
- **关键步骤**：
  1. 定义低维子空间 $K$（如 Krylov 子空间）。
  2. 在 $K$ 中寻找近似解 $\mathbf{x}_{\text{approx}}$，满足残量 $\mathbf{r} = \mathbf{b} - A\mathbf{x}_{\text{approx}}$ 与另一个子空间 $L$ 正交。

#### **例子：投影方法的几何直观**
假设原问题在三维空间中，我们选择二维平面 $K$ 作为子空间。投影方法的目标是：
- 在平面 $K$ 中找到一个点 $\mathbf{x}_{\text{approx}}$，使得残量 $\mathbf{r} = \mathbf{b} - A\mathbf{x}_{\text{approx}}$ 与某个约束空间 $L$ 正交（即垂直于 $L$ 中的所有向量）。

---

### **2.2 Krylov 子空间**
- **定义**：给定矩阵 $A$ 和初始残量 $\mathbf{r}_0$，Krylov 子空间为：
  $$
  K_m(A, \mathbf{r}_0) = \text{span}\{\mathbf{r}_0, A\mathbf{r}_0, A^2\mathbf{r}_0, \dots, A^{m-1}\mathbf{r}_0\}
  $$
- **特点**：嵌套性（$K_1 \subset K_2 \subset \dots$），适合迭代扩展。

#### **例子：构造 Krylov 子空间**
设 $A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix}$，初始残量 $\mathbf{r}_0 = [1, 0]^T$，则：
- $K_1 = \text{span}\{\mathbf{r}_0\}$
- $K_2 = \text{span}\{\mathbf{r}_0, A\mathbf{r}_0\} = \text{span}\left\{[1, 0]^T, [1, 3]^T\right\}$

---

## **第三步：Arnoldi 过程（构造正交基）**
### **3.1 目标**
为 Krylov 子空间 $K_m$ 构造一组标准正交基 $\{\mathbf{v}_1, \mathbf{v}_2, \dots, \mathbf{v}_m\}$。

### **3.2 Arnoldi 算法步骤**
1. **初始化**：$\mathbf{v}_1 = \mathbf{r}_0 / \|\mathbf{r}_0\|$
2. **迭代**（对 $j = 1$ 到 $m-1$）：
   - 计算 $\mathbf{w}_j = A\mathbf{v}_j$
   - 对 $i = 1$ 到 $j$：
     - $\mathbf{h}_{ij} = \mathbf{w}_j^T \mathbf{v}_i$
     - 更新 $\mathbf{w}_j = \mathbf{w}_j - \mathbf{h}_{ij}\mathbf{v}_i$
   - 归一化：$\mathbf{h}_{j+1,j} = \|\mathbf{w}_j\|$，$\mathbf{v}_{j+1} = \mathbf{w}_j / \mathbf{h}_{j+1,j}$

#### **例子：Arnoldi 过程**
设 $A = \begin{bmatrix} 1 & 0 \\ 0 & 2 \end{bmatrix}$，$\mathbf{r}_0 = [1, 1]^T$，构造 $K_2$ 的正交基：
1. **初始化**：
   - $\mathbf{r}_0 = [1, 1]^T$，$\|\mathbf{r}_0\| = \sqrt{1^2 + 1^2} = \sqrt{2}$
   - $\mathbf{v}_1 = [1/\sqrt{2}, 1/\sqrt{2}]^T$

2. **第一次迭代（j=1）**：
   - 计算 $\mathbf{w}_1 = A\mathbf{v}_1 = \begin{bmatrix} 1 & 0 \\ 0 & 2 \end{bmatrix} \begin{bmatrix} 1/\sqrt{2} \\ 1/\sqrt{2} \end{bmatrix} = \begin{bmatrix} 1/\sqrt{2} \\ 2/\sqrt{2} \end{bmatrix}$
   - 计算 $\mathbf{h}_{11} = \mathbf{w}_1^T \mathbf{v}_1 = (1/\sqrt{2})(1/\sqrt{2}) + (2/\sqrt{2})(1/\sqrt{2}) = 1.5$
   - 更新 $\mathbf{w}_1 = \mathbf{w}_1 - 1.5\mathbf{v}_1 = \begin{bmatrix} -0.5/\sqrt{2} \\ 0.5/\sqrt{2} \end{bmatrix}$
   - $\mathbf{h}_{21} = \|\mathbf{w}_1\| = \sqrt{(-0.5/\sqrt{2})^2 + (0.5/\sqrt{2})^2} = 0.5$
   - $\mathbf{v}_2 = \mathbf{w}_1 / 0.5 = [-1/\sqrt{2}, 1/\sqrt{2}]^T$

3. **结果**：
   - 正交基：$\mathbf{v}_1 = [1/\sqrt{2}, 1/\sqrt{2}]^T$, $\mathbf{v}_2 = [-1/\sqrt{2}, 1/\sqrt{2}]^T$
   - Hessenberg 矩阵：
     $$
     H_2 = \begin{bmatrix} 1.5 & 0.5 \\ 0 & 0 \end{bmatrix}
     $$

---

## **第四步：GMRES 方法（非对称问题）**
### **4.1 核心思想**
在仿射空间 $x^{(0)} + K_m$ 中找到 $\mathbf{x}$，使得残量 $\mathbf{r} = \mathbf{b} - A\mathbf{x}$ 的范数最小。

### **4.2 GMRES 计算步骤**
1. **初始化**：
   - 初始解 $\mathbf{x}^{(0)}$，初始残量 $\mathbf{r}_0 = \mathbf{b} - A\mathbf{x}^{(0)}$
   - $\beta = \|\mathbf{r}_0\|$, $\mathbf{v}_1 = \mathbf{r}_0 / \beta$

2. **Arnoldi 过程**：构造正交基 $V_m$ 和 Hessenberg 矩阵 $H_{m+1,m}$

3. **最小二乘问题**：
   - 求解 $\min_{\mathbf{y}} \|\beta \mathbf{e}_1 - H_{m+1,m} \mathbf{y}\|$
   - 其中 $\mathbf{e}_1 = [1, 0, \dots, 0]^T$

4. **更新解**：$\mathbf{x}^{(m)} = \mathbf{x}^{(0)} + V_m \mathbf{y}$

#### **例子：GMRES 求解**
设 $A = \begin{bmatrix} 1 & 1 \\ 0 & 2 \end{bmatrix}$，$\mathbf{b} = [3, 4]^T$，初始解 $\mathbf{x}^{(0)} = [0, 0]^T$：
1. **初始残量**：
   - $\mathbf{r}_0 = \mathbf{b} - A\mathbf{x}^{(0)} = [3, 4]^T$
   - $\beta = \|\mathbf{r}_0\| = 5$, $\mathbf{v}_1 = [3/5, 4/5]^T$

2. **Arnoldi 构造**（假设 $m=1$）：
   - $V_1 = [\mathbf{v}_1]$
   - $H_{2,1} = [ \mathbf{v}_1^T A \mathbf{v}_1 ] = [ \text{计算得 } h_{11} ]$

3. **最小二乘问题**：
   - $\min_y \|5 \cdot [1, 0]^T - H_{2,1} y\|$
   - 解得 $y = 5/h_{11}$

4. **更新解**：
   - $\mathbf{x}^{(1)} = \mathbf{x}^{(0)} + V_1 y$

（注：实际计算需完整执行 Arnoldi 步骤，此处简化说明流程。）

---

## **第五步：共轭梯度法（CG，对称正定问题）**
### **5.1 核心思想**
在 Krylov 子空间中寻找使能量泛函 $\|\mathbf{x} - \mathbf{x}^*\|_A$ 最小的解。

### **5.2 CG 算法步骤**
1. **初始化**：
   - 初始解 $\mathbf{x}_0$
   - 初始残量 $\mathbf{r}_0 = \mathbf{b} - A\mathbf{x}_0$
   - 搜索方向 $\mathbf{p}_0 = \mathbf{r}_0$

2. **迭代**（对 $k = 0, 1, \dots$）：
   - 计算步长 $\alpha_k = \frac{\mathbf{r}_k^T \mathbf{r}_k}{\mathbf{p}_k^T A \mathbf{p}_k}$
   - 更新解：$\mathbf{x}_{k+1} = \mathbf{x}_k + \alpha_k \mathbf{p}_k$
   - 更新残量：$\mathbf{r}_{k+1} = \mathbf{r}_k - \alpha_k A \mathbf{p}_k$
   - 计算 $\beta_k = \frac{\mathbf{r}_{k+1}^T \mathbf{r}_{k+1}}{\mathbf{r}_k^T \mathbf{r}_k}$
   - 更新搜索方向：$\mathbf{p}_{k+1} = \mathbf{r}_{k+1} + \beta_k \mathbf{p}_k$

#### **例子：CG 方法**
设 $A = \begin{bmatrix} 2 & 1 \\ 1 & 2 \end{bmatrix}$，$\mathbf{b} = [3, 4]^T$，初始解 $\mathbf{x}_0 = [0, 0]^T$：
1. **初始残量**：
   - $\mathbf{r}_0 = [3, 4]^T$
   - $\mathbf{p}_0 = \mathbf{r}_0$

2. **第一次迭代**：
   - $\alpha_0 = \frac{\mathbf{r}_0^T \mathbf{r}_0}{\mathbf{p}_0^T A \mathbf{p}_0} = \frac{3^2 + 4^2}{[3, 4]A[3, 4]^T} = \frac{25}{3 \cdot 7 + 4 \cdot 10} = \frac{25}{61}$
   - $\mathbf{x}_1 = \mathbf{x}_0 + \alpha_0 \mathbf{p}_0 = [75/61, 100/61]^T$
   - $\mathbf{r}_1 = \mathbf{b} - A\mathbf{x}_1$

---

## **第六步：重启策略（Restarted GMRES）**
### **6.1 动机**
避免存储和计算量随迭代步数 $m$ 增长。

### **6.2 重启流程**
1. 设定最大迭代步数 $m$，运行 GMRES 直到 $m$ 步。
2. 若未收敛，以当前解为新的初始解 $\mathbf{x}^{(0)}$，重新启动 GMRES。

#### **例子：重启 GMRES**
假设 $m=2$，每次迭代最多 2 步：
1. 第一次运行 GMRES，迭代 2 步得到近似解 $\mathbf{x}^{(2)}$。
2. 若残量不满足精度，令 $\mathbf{x}^{(0)} = \mathbf{x}^{(2)}$，重新运行 GMRES。

---

## **总结与考试策略**
1. **GMRES vs CG**：
   - 非对称问题用 GMRES，对称正定问题用 CG。
   - GMRES 需 Arnoldi 过程，CG 用三项递推公式。

2. **计算步骤记忆**：
   - Arnoldi：逐次正交化，生成 Hessenberg 矩阵。
   - GMRES：将问题转为最小二乘，用 Givens 旋转求解。
   - CG：记住 $\alpha_k, \beta_k$ 的计算公式。

3. **例题练习**：
   - 手动计算小规模（如 2x2）矩阵的 GMRES 或 CG 迭代步骤。
   - 理解残量范数如何随迭代减少。

4. **重启策略**：注意重启可能导致收敛变慢，但节省内存。

希望这份从零开始的详细讲解能帮你彻底掌握核心概念！如果需要更详细的例题或代码实现示例，请随时提问。